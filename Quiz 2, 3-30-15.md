#Machine Learning / SKLearn Quiz (Quiz 2)

1. Given the following machine learning matrix, fit each of the following algorithms into their respective places. Some may have multiple.

    .               | continuous          | categorical
    ---------------:|:--------------------|:-----------
    supervised    | regression          | classification
    unsupervised    | dimension reduction | clustering

    Algorithms:
    * Ordinary Least Squares â€” regression
    * Logistic Regression - regression
    * Naive Bayes - supervised
    * Decision Trees - classification
    * Support Vector Machines - classification / regression / supervised
    * Nearest Neighbors - clustering
    * K Means - clustering / unsupervised
    * Principal Component Analysis (Matrix Decomposition) - dimension reduction

2. Given the 4 entities in the matrix above, describe a problem / example we worked on in class for each, and provide one idea on your own.

In class, we used the Titanic data set to build out a classification tree based on the survival of individuals within certain demographic groups. Decision trees are particiularly useful when trying to identify relationships among various features and you're working with textual data.

3. All sklearn prediction objects have functions akin to fit(), transform(), predict(), and fit_transform(). Explain each in their most general terms.

-fit -- learn vocabulary dictionary of all tokens
-transform -- learn vocabulary dictionary; extracts raw text and produces into a n x m matrix
-predict -- used to compute / perform the operation
-fit_transform -- essentially a fit followed by a transform

3. Two of the above algorithms can use kernels (in their sklearn context)
a. Explain what a kernel does -- finds general types of relationships in datasets; essentially a similarity measure
b. Which are the two algorithms that use kernels? -- support vector machines; Naive Bayes

4. One of the above algorithms is most obviously not a linear solution to classification (it does not draw straight decision lines). Which algorithm is it, and how does it decide on decision lines?

Decision Trees -- decision rules and binary conditions dictate classification.

5. You are working on microarray (DNA) samples where number of observations (n) is 5 and number of observations (m) is > 10,000.
    1. Describe a supervised and unsupervised technique in order to reduce the number of features in the samples to those that are most significant.
    2. Compare the two techniques in their solution.

supervised -- decision trees; identify salient features and cut down based on hypothesized correlations
unspuervised -- principal component analysis -- convert observations into principal components and observe variance

6. Below is a table of Gini Importance (Normalized to 1) in predicting rent in New York City.
    1. Which algorithm uses Gini Importance?
    2. Interpret the table.

    Feature           | GiniImportance
    :-----------------|:--------------
    bedrooms          | 0.211
    bathrooms         | 0.005
    sqft              | 0.532
    distance subway   | 0.198
    distance columbus | 0.017
    nearby pizza      | 0.042

Decision trees -- Gini Importance is a measure of total variance across classes in a region. It is calculated as (G = 1-1/N)
Thus in the prior example, sqft is the feature with the greatest dispersion, followed by bedrooms.

7. What is the Receiving Operator Characteristic Curve? What two metrics is it composed of?

ROC curves are plots that illustrates performance of a binary classifier system; plots true positive against false positive at various thresholds.

9. How does a grid search work? Use an example algorithm from above to help explain it.

A grid search generates candidates from a grid of parameter values specified with the param_grid parameter. Ex) In the SVM algorithm, modifying kernal and gamma.

10. Three parts:
    1. What's your strongest "takeaway" from machine learning and this segment of the course?

Machine learning can be really interesting, but it's clear to me it's crucial to use many different algorithms to generate a compelling story about your dataset.

    2. Given a 2 dimensional figure where y=effort to learn and x=immediate usefulness, and slope = 1, what is one algorithm that felt above the slope (more effort to learn than usefulness) and one algorithm that felt below the slope (more usefulness than effort to learn)?

More effort than usefulness -- SVM 
More usefulness than effort to learn -- decision trees

    3. What's one question you still have about machine learning?

What's the best way to keep organized with the mental machine learning toolkit and to know when to use what?